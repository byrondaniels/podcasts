# Merge Transcript Lambda

AWS Lambda function that merges individual transcript chunks into a final, complete transcript.

## Overview

This Lambda function is part of the podcast transcription pipeline. It takes transcript chunks generated by the Whisper Lambda and combines them into a single formatted transcript file.

## Functionality

1. **Sort transcripts** by chunk_index to ensure correct order
2. **Download each chunk** transcript from S3
3. **Parse JSON** and extract text from each chunk
4. **Combine into single transcript** with proper formatting
5. **Add timestamps** every 5 minutes for easy navigation
6. **Save final transcript** to S3 as `transcripts/{episode_id}/final.txt`
7. **Update MongoDB** episode document with completion status

## Input Format

```json
{
  "episode_id": "ep123",
  "total_chunks": 12,
  "transcripts": [
    {
      "chunk_index": 0,
      "transcript_s3_key": "transcripts/ep123/chunk_0.json",
      "start_time_seconds": 0
    },
    {
      "chunk_index": 1,
      "transcript_s3_key": "transcripts/ep123/chunk_1.json",
      "start_time_seconds": 1200
    }
  ],
  "s3_bucket": "podcast-audio-bucket"
}
```

## Output Format

```json
{
  "episode_id": "ep123",
  "transcript_s3_key": "transcripts/ep123/final.txt",
  "total_words": 15000,
  "status": "completed"
}
```

## Transcript Formatting

The final transcript includes:
- Combined text from all chunks in order
- Paragraph breaks between chunks
- Timestamp headers every 5 minutes in format `[HH:MM:SS]`

Example output:
```
[00:00:00]
This is the beginning of the podcast transcript...

This is the content from the second chunk...

[00:05:00]
After five minutes, a new timestamp appears...
```

## MongoDB Update

Updates the episode document:
```javascript
episodes.update_one(
  {"episode_id": episode_id},
  {"$set": {
    "status": "completed",
    "transcript_s3_key": "transcripts/ep123/final.txt",
    "processed_at": ISODate("2024-01-15T12:00:00Z")
  }}
)
```

## Error Handling

- Validates all required input parameters
- Checks for missing chunks before processing
- Updates MongoDB with error status if processing fails
- Returns detailed error messages in output

## Configuration

### Environment Variables

- `MONGODB_URI` - MongoDB connection string (required)
- `MONGODB_DB_NAME` - MongoDB database name (default: "podcast_db")
- `S3_BUCKET` - Default S3 bucket name
- `LOG_LEVEL` - Logging level (default: "INFO")

### Lambda Configuration

- **Runtime**: Python 3.11
- **Memory**: 512 MB
- **Timeout**: 120 seconds (2 minutes)
- **Concurrency**: 5 reserved concurrent executions
- **Ephemeral Storage**: 512 MB

## Dependencies

- `boto3` - AWS SDK for S3 operations
- `pymongo` - MongoDB driver for database updates

See `lambda/requirements.txt` for specific versions.

## Deployment

### Prerequisites

1. AWS CLI configured with appropriate credentials
2. Terraform >= 1.0
3. S3 bucket for transcripts
4. MongoDB instance with appropriate collections

### Steps

1. Copy and configure variables:
   ```bash
   cp terraform.tfvars.example terraform.tfvars
   # Edit terraform.tfvars with your values
   ```

2. Initialize Terraform:
   ```bash
   terraform init
   ```

3. Review the plan:
   ```bash
   terraform plan
   ```

4. Deploy:
   ```bash
   terraform apply
   ```

### Required Variables

- `mongodb_uri` - MongoDB connection string
- `s3_bucket` - S3 bucket name

### Optional Variables

- `aws_region` (default: "us-east-1")
- `environment` (default: "dev")
- `function_name` (default: "merge-transcript-chunks")
- `lambda_timeout` (default: 120)
- `lambda_memory_size` (default: 512)
- `enable_monitoring` (default: true)

## Monitoring

CloudWatch alarms are automatically created (when `enable_monitoring = true`):

- **Errors Alarm**: Triggers when > 5 errors occur in 5 minutes
- **Throttles Alarm**: Triggers when > 2 throttles occur in 5 minutes
- **Duration Alarm**: Triggers when average duration exceeds 90% of timeout

## Logs

Logs are available in CloudWatch Logs:
- Log Group: `/aws/lambda/merge-transcript-chunks`
- Retention: 30 days (configurable)

## IAM Permissions

The Lambda function has permissions to:
- Read/write objects in the configured S3 bucket
- List bucket contents
- Write CloudWatch Logs

## Testing

Test the Lambda function with the AWS CLI:

```bash
aws lambda invoke \
  --function-name merge-transcript-chunks \
  --payload file://test-event.json \
  response.json
```

Example `test-event.json`:
```json
{
  "episode_id": "test-ep-001",
  "total_chunks": 2,
  "transcripts": [
    {
      "chunk_index": 0,
      "transcript_s3_key": "transcripts/test-ep-001/chunk_0.json",
      "start_time_seconds": 0
    },
    {
      "chunk_index": 1,
      "transcript_s3_key": "transcripts/test-ep-001/chunk_1.json",
      "start_time_seconds": 1200
    }
  ]
}
```

## Integration with Step Functions

This Lambda is designed to be called as the final step in a Step Functions state machine after all transcript chunks have been processed by the Whisper Lambda.

Example Step Functions task:
```json
{
  "Type": "Task",
  "Resource": "arn:aws:lambda:us-east-1:123456789012:function:merge-transcript-chunks",
  "InputPath": "$",
  "ResultPath": "$.mergeResult",
  "Next": "NotifyCompletion"
}
```

## Outputs

Terraform outputs:
- `lambda_function_name` - Lambda function name
- `lambda_function_arn` - Lambda ARN
- `lambda_role_arn` - IAM role ARN
- `cloudwatch_log_group_name` - Log group name
- `lambda_invoke_arn` - Invoke ARN for Step Functions

## Troubleshooting

### Missing Chunks Error

If you receive "Missing chunks" error:
1. Check that all Whisper Lambda invocations completed successfully
2. Verify chunk indices in the input match expected sequence
3. Check S3 for missing transcript chunk files

### MongoDB Connection Error

If MongoDB connection fails:
1. Verify `MONGODB_URI` is correctly formatted
2. Check network connectivity from Lambda to MongoDB
3. Ensure IP whitelist includes Lambda's NAT gateway (if using MongoDB Atlas)
4. Verify database authentication credentials

### S3 Access Errors

If S3 operations fail:
1. Verify the S3 bucket exists and is accessible
2. Check IAM role has required S3 permissions
3. Ensure transcript chunk files exist at expected S3 keys

## License

Part of the podcast transcription system.
